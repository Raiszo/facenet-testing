{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# from data_utils import *\n",
    "#import classifiers.lstm as cell\n",
    "from image_utils import load_image, preprocess_image, load_image_batch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# use only square images\n",
    "face_test = preprocess_image(load_image('test_images/george.jpg', size=160))\n",
    "face_batch = np.expand_dims(face_test, axis=0)\n",
    "print(face_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph('./pretrainned-model/model-20180402-114759.meta')\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 160, 160, 3)\n",
      "(?, 512)\n",
      "INFO:tensorflow:Restoring parameters from ./pretrainned-model/model-20180402-114759.ckpt-275\n",
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "embeddings = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "print(images_placeholder.shape)\n",
    "print(embeddings.shape)\n",
    "\n",
    "\n",
    "with get_session() as sess_test:\n",
    "    saver.restore(sess_test, './pretrainned-model/model-20180402-114759.ckpt-275')\n",
    "    # Run forward pass to calculate embeddings\n",
    "    feed_dict = {\n",
    "        images_placeholder: face_batch, \n",
    "        phase_train_placeholder:False \n",
    "    }\n",
    "    emb = sess_test.run(embeddings, feed_dict=feed_dict)\n",
    "    print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# use only square images\n",
    "image_paths = [\n",
    "    'test_images/george.jpg',\n",
    "    'test_images/ebert.jpg',\n",
    "    'test_images/ebert2.jpg',\n",
    "    'test_images/ebert_dni.jpg'\n",
    "]\n",
    "images = load_image_batch(image_paths, size=160)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./pretrainned-model/model-20180402-114759.ckpt-275\n",
      "1 with 2 1.1867632\n",
      "1 with 3 1.1089562\n",
      "1 with 4 1.3747356\n",
      "2 with 3 0.77131104\n",
      "2 with 4 1.1783515\n",
      "3 with 4 1.1392387\n",
      "(3, 512)\n"
     ]
    }
   ],
   "source": [
    "with get_session() as sess_batch:\n",
    "    saver.restore(sess_batch, './pretrainned-model/model-20180402-114759.ckpt-275')\n",
    "    # Run forward pass to calculate embeddings\n",
    "    feed_dict = {\n",
    "        images_placeholder: images, \n",
    "        phase_train_placeholder:False \n",
    "    }\n",
    "    img_embs = sess_batch.run(embeddings, feed_dict=feed_dict)\n",
    "    \n",
    "    print(\"1 with 2\", np.linalg.norm(img_embs[0] - img_embs[1]))\n",
    "    print(\"1 with 3\", np.linalg.norm(img_embs[0] - img_embs[2]))\n",
    "    print(\"1 with 4\", np.linalg.norm(img_embs[0] - img_embs[3]))\n",
    "    print(\"2 with 3\", np.linalg.norm(img_embs[1] - img_embs[2]))\n",
    "    print(\"2 with 4\", np.linalg.norm(img_embs[1] - img_embs[3]))\n",
    "    print(\"3 with 4\", np.linalg.norm(img_embs[2] - img_embs[3]))\n",
    "    print(emb.shape)\n",
    "    \"\"\"\n",
    "    INFO:tensorflow:Restoring parameters from ./pretrainned-model/model-20180402-114759.ckpt-275\n",
    "    1 with 2 1.1867632\n",
    "    1 with 3 1.1089562\n",
    "    1 with 4 1.3747356\n",
    "    2 with 3 0.77131104\n",
    "    2 with 4 1.1783515\n",
    "    3 with 4 1.1392387\n",
    "    (3, 512)\n",
    "    \n",
    "    At least 1 with 4 is greater than the other ones, need to fine tune the network for the correct images\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
